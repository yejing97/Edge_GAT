{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npz = np.load('/home/e19b516g/yejing/data/data_for_graph/npz/val/form_5_648_E3236.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(npz['edge_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([[0,1],[1,0]])\n",
    "# fill the diagonal with 1\n",
    "a.fill_diagonal_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(npz['strokes_emb'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(npz['stroke_labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "nn = torch.empty(0, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.ones(10,100,2)\n",
    "nn = torch.cat((nn, emb), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = torch.cat((nn, torch.zeros(3,100,2)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.load('/home/e19b516g/yejing/data/data_for_graph/S100_R5_Speed_False/val_y.pt')\n",
    "X = torch.load('/home/e19b516g/yejing/data/data_for_graph/S100_R5_Speed_False/val_X.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "s = get_splits(y, valid_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tuple sss[1] 0~100, sss[2] 101~200\n",
    "sss = (list(range(0,12)), list(range(12,20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = torch.load('/home/e19b516g/yejing/code/Edge_GAT/pretrain_logs/S100_R5_Speed_False_lr_0.001/version_1/checkpoints/epoch=22-step=120037.ckpt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.LitModel import LitModel\n",
    "model = LitModel(\n",
    "    node_input_size = 100,\n",
    "    edge_input_size = 20,\n",
    "    gat_input_size = 128,\n",
    "    gat_hidden_size = 64,\n",
    "    gat_output_size = 128,\n",
    "    gat_n_heads = 8,\n",
    "    node_class_nb = 114,\n",
    "    edge_class_nb = 14,\n",
    "    dropout = 0.6,\n",
    "    lambda1 = 0.5,\n",
    "    lambda2 =  0.5,\n",
    "    lr = 1e-3,\n",
    "    device = 'cpu'\n",
    ")\n",
    "# model.load_state_dict(ckpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(ckpt, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_state_dict = OrderedDict()\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    # print(k, v.shape)\n",
    "    # print(k[:6] + 'node_emb.' + k[6:])\n",
    "    new_state_dict[k[:6] + 'node_emb.' + k[6:]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pre_train\n",
    "model_x = pre_train.LightModel()\n",
    "model_x.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[1,2,3],[4,5,6]])\n",
    "test.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = '/home/e19b516g/yejing/data/data_for_graph/npz/train'\n",
    "node_nb = []\n",
    "edge_nb = []\n",
    "for _, _, files in os.walk(npz_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.npz'):\n",
    "            npz =np.load(os.path.join(npz_path, file))\n",
    "            node_nb.append(npz['strokes_emb'].shape[0])\n",
    "            edge_nb.append(np.sum(npz['los'] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = np.load('/home/e19b516g/yejing/data/data_for_graph/npz/train/001-equation000.npz')\n",
    "nnn['edge_labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.array(node_nb), bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_nb = np.array(node_nb)\n",
    "node_nb.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(edge_nb), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_graphs(node_counts, edge_counts, nodes_per_group):\n",
    "    # Calculate the total number of nodes and groups\n",
    "    total_nodes = sum(node_counts)\n",
    "    num_groups = total_nodes // nodes_per_group\n",
    "    \n",
    "    # Initialize groups\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    \n",
    "    # Create a list of (index, node_count, edge_count) tuples\n",
    "    graphs = list(enumerate(zip(node_counts, edge_counts)))\n",
    "    \n",
    "    # Sort graphs in descending order of edge_counts\n",
    "    sorted_graphs = sorted(graphs, key=lambda x: x[1][1], reverse=True)\n",
    "    \n",
    "    # Distribute graphs into groups\n",
    "    for index, (nodes, edges) in sorted_graphs:\n",
    "        for group in groups:\n",
    "            if sum(graphs[i][1][0] for i in group) + nodes <= nodes_per_group:\n",
    "                group.append(index)\n",
    "                break\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Example usage:\n",
    "# node_counts = [10, 15, 8, 12, 7]  # List of node counts\n",
    "# edge_counts = [20, 30, 25, 18, 14]  # List of edge counts\n",
    "# num_groups = 2  # Set the number of groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def balance_graphs(node_counts, edge_counts, nodes_per_group):\n",
    "    num_groups = sum(node_counts) // nodes_per_group\n",
    "    num_graphs = len(node_counts)\n",
    "\n",
    "    # Calculate the total number of edges\n",
    "    total_edges = sum(edge_counts)\n",
    "\n",
    "    # Sort graphs by edge counts in ascending order\n",
    "    sorted_graphs = sorted(enumerate(edge_counts), key=lambda x: x[1])\n",
    "\n",
    "    # Initialize group assignments\n",
    "    group_assignments = [-1] * num_graphs\n",
    "\n",
    "    # Initialize group statistics\n",
    "    group_node_sums = [0] * num_groups\n",
    "    group_edge_sums = [0] * num_groups\n",
    "\n",
    "    for graph_idx, edge_count in sorted_graphs:\n",
    "        # Try to add the graph to the group with the smallest sum of nodes\n",
    "        min_group = group_node_sums.index(min(group_node_sums))\n",
    "        if group_assignments[graph_idx] == -1:\n",
    "            if group_node_sums[min_group] + node_counts[graph_idx] <= nodes_per_group:\n",
    "                group_assignments[graph_idx] = min_group\n",
    "                group_node_sums[min_group] += node_counts[graph_idx]\n",
    "                group_edge_sums[min_group] += edge_count\n",
    "\n",
    "    # If there are unassigned graphs, assign them to the group with the smallest edge sum\n",
    "    for graph_idx, edge_count in sorted_graphs:\n",
    "        if group_assignments[graph_idx] == -1:\n",
    "            min_group = group_edge_sums.index(min(group_edge_sums))\n",
    "            group_assignments[graph_idx] = min_group\n",
    "            group_edge_sums[min_group] += edge_count\n",
    "\n",
    "    # Organize the groups\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    for graph_idx, group_idx in enumerate(group_assignments):\n",
    "        groups[group_idx].append(graph_idx)\n",
    "    return groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = balance_graphs(node_nb, edge_nb, 128)\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    node_sum = 0\n",
    "    edge_sum = 0\n",
    "    print(f'Group {i}:')\n",
    "    for index in group:\n",
    "        nodes, edges = node_nb[index], edge_nb[index]\n",
    "        node_sum += nodes\n",
    "        edge_sum += edges\n",
    "        print(f'  Graph {index + 1} with {nodes} nodes and {edges} edges')\n",
    "    print(f'  Total: {node_sum} nodes and {edge_sum} edges\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.Datamodule import CROHMEDatamodule\n",
    "dm = CROHMEDatamodule(\n",
    "    root_path = npz_path,\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    "    reload_dataloaders_every_n_epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['N2E20_form_5_673_E3363', 'N5E29_form_5_673_E3363', 'N25E290_form_5_673_E3363']\n",
    "# get number behind N and E in the list\n",
    "import re\n",
    "node_nb = []\n",
    "edge_nb = []\n",
    "for i in list:\n",
    "    n = i.split('_')[0]\n",
    "    node_nb.append(n.split('E')[0].split('N')[1])\n",
    "    edge_nb.append(n.split('E')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rand = torch.rand(3, 3, 4, 5)\n",
    "xx = torch.zeros(0, 0, 4, 5)\n",
    "xx = torch.cat((xx, x_rand), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "g_ = torch.rand(3, 8, 64)\n",
    "g_r = g_.repeat(3, 1, 1)\n",
    "g_r_i = g_.repeat_interleave(3, dim=0)\n",
    "print(g_r.shape)\n",
    "print(g_r_i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(9, 8, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_con = torch.cat([g_r, g_r_i], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([g_r, g_r_i, b], dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npz = np.load('/home/e19b516g/yejing/data/data_for_graph/S150_R10/train/N15E128_form_023_E178.npz')\n",
    "print(npz['edge_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los = npz['los']\n",
    "el = npz['edge_labels']\n",
    "los = torch.from_numpy(los)\n",
    "el = torch.from_numpy(el)\n",
    "los = torch.triu(los)\n",
    "indices = torch.nonzero(los.reshape(-1))\n",
    "el = el.reshape(-1)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pt = torch.load('/home/e19b516g/yejing/code/Edge_GAT/val_results/2024_01_05_06_13_30/version_0/epoch_90.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_pred = torch.zeros(0)\n",
    "edge_pred = torch.zeros(0)\n",
    "node_label = torch.zeros(0)\n",
    "edge_label = torch.zeros(0)\n",
    "for i in pt:\n",
    "    node_hat = torch.argmax(i[0], dim=1)\n",
    "    node_pred = torch.cat((node_pred, node_hat), dim=0)\n",
    "    stroke_label = i[1]\n",
    "    node_label = torch.cat((node_label, stroke_label), dim=0)\n",
    "    edge_hat = torch.argmax(i[2], dim=1)\n",
    "    edge_pred = torch.cat((edge_pred, edge_hat), dim=0)\n",
    "    rel_label = i[3]\n",
    "    edge_label = torch.cat((edge_label, rel_label), dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.nonzero(edge_label.reshape(-1))\n",
    "edge_label = edge_label.reshape(-1)[indices]\n",
    "edge_pred = edge_pred.reshape(-1)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(node_label, node_pred))\n",
    "print(accuracy_score(edge_label, edge_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(edge_label, edge_pred)\n",
    "cm_node = confusion_matrix(node_label, node_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(26))\n",
    "# disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = cm_node.shape[0]\n",
    "class_accuracies = {}\n",
    "for i in range(num_classes):\n",
    "    class_accuracies[f\"Class_{i}\"] = cm_node[i, i] / cm_node[i].sum()\n",
    "\n",
    "# Print accuracy for each class\n",
    "for key, value in class_accuracies.items():\n",
    "    print(f\"Accuracy for {key}: {value:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = cm.shape[0]\n",
    "class_accuracies = {}\n",
    "for i in range(num_classes-1):\n",
    "    class_accuracies[f\"Class_{i}\"] = cm[i, i] / cm[i].sum()\n",
    "\n",
    "# Print accuracy for each class\n",
    "for key, value in class_accuracies.items():\n",
    "    print(f\"Accuracy for {key}: {value:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 20))  # Change the figure size as needed\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (edge_label == edge_pred).sum().item() / edge_label.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(torch.argmax(pt[3][0], dim=1), pt[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npz = np.load('/home/e19b516g/yejing/data/data_for_graph/S100_R5_Speed_False/test/N9E54_form_5_237_E1183.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_l = npz['edge_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los = npz['los']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(adj_matrix, start, end, visited=None, path=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if path is None:\n",
    "        path = []\n",
    "\n",
    "    # Mark the current node as visited and add it to the path\n",
    "    visited.add(start)\n",
    "    path.append(start)\n",
    "\n",
    "    # If the current node is the destination, return the path\n",
    "    if start == end:\n",
    "        return path\n",
    "\n",
    "    # Check neighbors of the current node\n",
    "    for node, connected in enumerate(adj_matrix[start]):\n",
    "        if connected and node not in visited:\n",
    "            # Recursively call find_path for unvisited neighbors\n",
    "            new_path = find_path(adj_matrix, node, end, visited, path)\n",
    "            if new_path:\n",
    "                return new_path\n",
    "\n",
    "    # If no path is found, backtrack\n",
    "    path.pop()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_below_diagonal_to_zero(matrix):\n",
    "    rows, cols = np.tril_indices(matrix.shape[0], k=-1)  # Get indices below the diagonal\n",
    "    matrix[rows, cols] = 0  # Set elements below the diagonal to 0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge_l = set_below_diagonal_to_zero(edge_l)\n",
    "new_edge_l = np.where(new_edge_l == 1, 0, new_edge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(los)\n",
    "print(edge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(los.shape[0]):\n",
    "    for j in range(i+1, los.shape[0]):\n",
    "        if los[i][j] == 1 and edge_l[i][j] == 0:\n",
    "            path = find_path(new_edge_l, i, j)\n",
    "            print(i,j)\n",
    "            print(path)\n",
    "            if path is not None:\n",
    "                new_edge_l[i][j] = edge_l[path[0]][path[1]]\n",
    "                print(edge_l[path[0]][path[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.tensor(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.triu(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_npz = np.load('/home/e19b516g/yejing/data/data_for_graph/S50_R5_equation/train/N10E60_form_5_769_E3845.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_npz['edge_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_npz['los']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing.load import load_gt\n",
    "inkml = '/home/e19b516g/yejing/data/data_for_graph/INKML/train/CROHME2023_train/form_002_E12.inkml'\n",
    "lg = '/home/e19b516g/yejing/data/data_for_graph/LG/train/CROHME2023_train/form_002_E12.lg'\n",
    "s, sl, el, los = load_gt(inkml, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_b = torch.zeros(100, 100)\n",
    "start = 0\n",
    "los_b[start:start+los.shape[0], start:start+los.shape[0]] = los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_b = torch.zeros(100, 100)\n",
    "label_b[start:start+los.shape[0], start:start+los.shape[0]] = torch.tensor(npz['edge_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=np.inf)\n",
    "print(label_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(los_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "for _, _, files in os.walk('/home/e19b516g/yejing/data/data_for_graph/S150_R10/train'):\n",
    "    for file in files:\n",
    "        if file.endswith('.npz'):\n",
    "            npz = np.load(os.path.join('/home/e19b516g/yejing/data/data_for_graph/S150_R10/train', file))\n",
    "            label = npz['edge_labels']\n",
    "            print(label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.Dataset import CROHMEDataset\n",
    "ds = CROHMEDataset(\n",
    "    data_type='train',\n",
    "    root_path='/home/e19b516g/yejing/data/data_for_graph/S100_R10',\n",
    "    batch_size=128,\n",
    "    max_node=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter(edges_emb, edges_label, los):\n",
    "    los = los.squeeze().fill_diagonal_(0)\n",
    "    los = torch.triu(los)\n",
    "    indices = torch.nonzero(los.reshape(-1)).squeeze()\n",
    "    edges_label = edges_label[indices]\n",
    "    edges_emb = edges_emb.reshape(-1, edges_emb.shape[-1])[indices]\n",
    "    return edges_emb, edges_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strokes, relations, los, s_label, r_label = ds.__getitem__(20)\n",
    "for i in range(ds.__len__()):\n",
    "    strokes, relations, los, s_label, r_label = ds.__getitem__(i)\n",
    "    _, new_edge_l = edge_filter(relations, r_label.reshape(-1), los)\n",
    "    print(torch.where(new_edge_l == 0, 1, 0).sum())\n",
    "    # calculate number of 0 in new_edge_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "npz_path = '/home/e19b516g/yejing/data/data_for_graph/S100_R10/train/'\n",
    "for _, _, files in os.walk(npz_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.npz'):\n",
    "            print(file)\n",
    "            npz = np.load(os.path.join(npz_path, file))\n",
    "            new_los = torch.triu(torch.tensor(npz['los']))\n",
    "            indices = torch.nonzero(new_los.reshape(-1)).squeeze()\n",
    "            label = torch.tensor(npz['edge_labels']).reshape(-1)\n",
    "            new_label = label[indices]\n",
    "            print(new_label.max())\n",
    "            print(torch.where(new_label == 0, 1, 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(npz_path, 'N8E56_formulaire028-equation062.npz')\n",
    "npz_p = np.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_p['edge_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_p['los']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(3,100)\n",
    "x_re = x.repeat(1, 3).reshape(3, 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_n = x_re.fill_diagonal_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(5, 3, 3)\n",
    "t2 = t1 * (1-torch.eye(3, 3).repeat(5, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(5, 3, 3)\n",
    "t + torch.eye(3, 3).repeat(5, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor 3*4, the value of the first column is 1, the value of the second column is 2, and so on\n",
    "test = torch.arange(1, 5).repeat(3, 1).T\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_los = torch.zeros(128, 128)\n",
    "los = torch.rand(16, 8, 8)\n",
    "for i in range(los.shape[0]):\n",
    "    new_los[i*los.shape[1]:(i+1)*los.shape[1], i*los.shape[1]:(i+1)*los.shape[1]] = los[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_los[5:14, 5:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = torch.arange(16) * 8\n",
    "new_los[indices[:, None], indices] = los.view(-1, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(3, 3, 5)\n",
    "print(t)\n",
    "torch.diagonal(t).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_piece_positions(shape, padding_size):\n",
    "    total_length = shape\n",
    "    start = 0\n",
    "    positions = []\n",
    "    \n",
    "    while start < total_length:\n",
    "        end = min(start + 8, total_length)\n",
    "        positions.append([start, end])\n",
    "        start = end\n",
    "    \n",
    "    if padding_size > 0:\n",
    "        positions[0][0] -= padding_size  # Adjust the start position for the first piece\n",
    "        \n",
    "        # Adjust the end position for the last piece if there's padding\n",
    "        last_piece_index = len(positions) - 1\n",
    "        positions[last_piece_index][1] += padding_size\n",
    "        \n",
    "        # Adjust the end position of the last piece if it exceeds the total length\n",
    "        if positions[last_piece_index][1] > total_length:\n",
    "            positions[last_piece_index][1] = total_length\n",
    "    \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(name, shape, pad):\n",
    "    list = []\n",
    "    list.append([name, shape, 0, 8 - pad])\n",
    "    start = 8 - pad\n",
    "    nb = math.ceil((shape + pad) / 8)\n",
    "    for i in range(nb - 1):\n",
    "        if i == nb - 2:\n",
    "            end = shape\n",
    "        else:\n",
    "            end = start + 8\n",
    "        list.append([name, shape, start, end])\n",
    "        start += 8\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "padding('miaom',80, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(10, 10)\n",
    "t[8:10,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npz = np.load('/home/e19b516g/yejing/data/data_for_graph/S100_R10/test/N10E42_form_315_E2513.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(npz['edges_emb']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(batch):\n",
    "    strokes_emb, edges_emb, los, strokes_label, edges_label = batch\n",
    "    strokes_emb = strokes_emb\n",
    "    strokes_emb = strokes_emb.reshape(strokes_emb.shape[0]*strokes_emb.shape[1], strokes_emb.shape[2], strokes_emb.shape[3])\n",
    "    edges_emb = edges_emb.squeeze(0).reshape(edges_emb.shape[0],edges_emb.shape[1], edges_emb.shape[2], edges_emb.shape[3]* edges_emb.shape[4])\n",
    "    strokes_label = strokes_label.squeeze(0).long().reshape(-1)\n",
    "    edges_label = edges_label.squeeze(0).long()\n",
    "    # los = los.squeeze(0).fill_diagonal_(1).unsqueeze(-1)\n",
    "    los = los + torch.eye(los.shape[1], los.shape[2]).repeat(los.shape[0], 1, 1)\n",
    "    new_los = torch.zeros((los.shape[0]*los.shape[1], los.shape[0]*los.shape[2]))\n",
    "    new_edges_label = torch.zeros((edges_label.shape[0]*edges_label.shape[1], edges_label.shape[0]*edges_label.shape[2])).long()\n",
    "    new_edges_emb = torch.zeros((edges_emb.shape[0]*edges_emb.shape[1], edges_emb.shape[0]*edges_emb.shape[2], edges_emb.shape[3]))\n",
    "    for i in range(los.shape[0]):\n",
    "        new_los[i*los.shape[1]:(i+1)*los.shape[1], i*los.shape[1]:(i+1)*los.shape[1]] = los[i]\n",
    "        new_edges_label[i*edges_label.shape[1]:(i+1)*edges_label.shape[1], i*edges_label.shape[1]:(i+1)*edges_label.shape[1]] = edges_label[i]\n",
    "        new_edges_emb[i*edges_emb.shape[1]:(i+1)*edges_emb.shape[1], i*edges_emb.shape[1]:(i+1)*edges_emb.shape[1]] = edges_emb[i]\n",
    "    return strokes_emb, new_edges_emb, new_los.unsqueeze(-1), strokes_label, new_edges_label.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset.Datamodule import CROHMEDatamodule\n",
    "dm = CROHMEDatamodule(\n",
    "    root_path = '/home/e19b516g/yejing/data/data_for_graph/S100_R10',\n",
    "    shuffle = True,\n",
    "    num_workers = 0,\n",
    "    batch_size = 8,\n",
    "    max_node = 8,\n",
    "    reload_dataloaders_every_n_epochs=1\n",
    ")\n",
    "dm.setup('fit')\n",
    "for batch in dm.train_dataloader():\n",
    "    try:\n",
    "        r = load_batch(batch)\n",
    "    except:\n",
    "        print('error')\n",
    "        print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "strokes_emb = np.load('/home/e19b516g/yejing/data/data_for_graph/S150_R10/train/strokes_emb/N12E84_formulaire017-equation059.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke = strokes_emb[5]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(stroke[:, 0], -stroke[:, 1], marker='o', linestyle='-')\n",
    "plt.title('Stroke Plot')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.rand(3, 3, 5).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.where(t == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(8, 3, 3, 10)\n",
    "mean = data.mean(dim=(0,1,2), keepdim=True)\n",
    "std = data.std(dim=(0,1, 2), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(mean.shape)\n",
    "print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((data- mean)/std).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los = torch.eye(3, 3)\n",
    "am = torch.ones(3, 3)\n",
    "print(am  los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_curvature(stroke):\n",
    "    # Check for minimum number of points required for curvature calculation\n",
    "    if len(stroke) < 3:\n",
    "        raise ValueError(\"At least three points are required for curvature calculation\")\n",
    "\n",
    "    # Convert the list of points to numpy array for easy calculations\n",
    "    stroke = np.array(stroke)\n",
    "\n",
    "    # Calculate first derivatives\n",
    "    dx = np.gradient(stroke[:, 0])\n",
    "    dy = np.gradient(stroke[:, 1])\n",
    "\n",
    "    # Calculate second derivatives\n",
    "    ddx = np.gradient(dx)\n",
    "    ddy = np.gradient(dy)\n",
    "\n",
    "    # Calculate curvature using the formula: curvature = |dx * ddy - dy * ddx| / (dx^2 + dy^2)^(3/2)\n",
    "    curvature = np.abs(dx * ddy - dy * ddx) / (dx**2 + dy**2)**(3/2)\n",
    "\n",
    "    return curvature\n",
    "\n",
    "# Example stroke (list of points)\n",
    "stroke = [(1, 5), (3, 2), (5, 6), (7, 8), (9, 10)]\n",
    "\n",
    "# Calculate curvature for the stroke\n",
    "curvatures = calculate_curvature(stroke)\n",
    "\n",
    "print(\"Curvatures at each point:\")\n",
    "print(curvatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes_emb = np.load('/home/e19b516g/yejing/data/data_for_graph/S100geo_feat/val/strokes_emb/N4E10_form_080_E638.npy')\n",
    "print(strokes_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "src_path = '/home/e19b516g/yejing/data/data_for_graph/S150_R10/'\n",
    "tgt_path = '/home/e19b516g/yejing/data/data_for_graph/S150_R10_new/'\n",
    "for root, dirs, files in os.walk(src_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.npz'):\n",
    "            tag = root.split('/')[-1]\n",
    "            file_name = file.split('.')[0]\n",
    "            data = np.load(os.path.join(root, file))\n",
    "            if not os.path.exists(os.path.join(tgt_path, tag, 'strokes_emb')):\n",
    "                os.makedirs(os.path.join(tgt_path, tag, 'strokes_emb'))\n",
    "            np.save(os.path.join(tgt_path, tag, 'strokes_emb', file_name), data['strokes_emb'])\n",
    "            if not os.path.exists(os.path.join(tgt_path, tag, 'edges_emb')):\n",
    "                os.makedirs(os.path.join(tgt_path, tag, 'edges_emb'))\n",
    "            np.save(os.path.join(tgt_path, tag, 'edges_emb', file_name), data['edges_emb'])\n",
    "            if not os.path.exists(os.path.join(tgt_path, tag, 'los')):\n",
    "                os.makedirs(os.path.join(tgt_path, tag, 'los'))\n",
    "            np.save(os.path.join(tgt_path, tag, 'los', file_name), data['los'])\n",
    "            if not os.path.exists(os.path.join(tgt_path, tag, 'stroke_labels')):\n",
    "                os.makedirs(os.path.join(tgt_path, tag, 'stroke_labels'))\n",
    "            np.save(os.path.join(tgt_path, tag, 'stroke_labels', file_name), data['stroke_labels'])\n",
    "            if not os.path.exists(os.path.join(tgt_path, tag, 'edge_labels')):\n",
    "                os.makedirs(os.path.join(tgt_path, tag, 'edge_labels'))\n",
    "            np.save(os.path.join(tgt_path, tag, 'edge_labels', file_name), data['edge_labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing.LG.lg import Lg\n",
    "lg = Lg('/home/e19b516g/yejing/data/data_for_graph/LG/val/CROHME2023_val/form_5_648_E3236.lg').segmentGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_root_path = '/home/e19b516g/yejing/data/data_for_graph/LG/'\n",
    "symbol_list = []\n",
    "for root, dirs, files in os.walk(lg_root_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.lg'):\n",
    "            lg = Lg(os.path.join(root, file)).segmentGraph()\n",
    "            for key in lg[0]:\n",
    "                symbol_list.append(lg[0][key][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(symbol_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "occurrences = Counter(symbol_list).most_common()\n",
    "lg_dic = []\n",
    "for xxx in occurrences:\n",
    "    lg_dic.append(xxx[0])\n",
    "# Print occurrences of each string\n",
    "# for string, count in occurrences.items():\n",
    "#     print(f\"'{string}' occurs {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(lg_dic) -set(ink_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "doc_namespace = \"{http://www.w3.org/2003/InkML}\"\n",
    "def load_inkml(file_path):\n",
    "    strokes = []\n",
    "    labels = []\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    last_stroke = []\n",
    "    dic = {}\n",
    "    for trace_tag in root.findall(doc_namespace + 'traceGroup'):\n",
    "        for trace_tag in trace_tag.findall(doc_namespace + 'traceGroup'):\n",
    "            for annotation in trace_tag.findall(doc_namespace + 'annotation'):\n",
    "                label = annotation.text\n",
    "            for traceview in trace_tag.findall(doc_namespace + 'traceView'):\n",
    "                s_id = traceview.get('traceDataRef')\n",
    "                dic[s_id] = label\n",
    "    for trace_tag in root.findall(doc_namespace + 'trace'):\n",
    "        points = []\n",
    "        last_point = (0, 0)\n",
    "        for coord in (trace_tag.text).replace('\\n', '').split(','):\n",
    "            this_point = (float(coord.strip().split(' ')[0]), float(coord.strip().split(' ')[1]))\n",
    "            if this_point != last_point:\n",
    "                points.append(this_point)\n",
    "                last_point = this_point\n",
    "        for coord in trace_tag.items():\n",
    "            id = coord[1]\n",
    "        if last_stroke != points:\n",
    "            strokes.append(points)\n",
    "            points_np = np.array(points)\n",
    "            if np.isnan(points_np).any() == True:\n",
    "                print(file_path)\n",
    "            if dic.__contains__(id):\n",
    "                labels.append(dic[id])\n",
    "            else:\n",
    "                labels.append('None')\n",
    "                dic[id] = 'None'\n",
    "        last_stroke = points\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inkml_root_path = '/home/e19b516g/yejing/data/data_for_graph/INKML/'\n",
    "symbol_list_ink = []\n",
    "for root, dirs, files in os.walk(inkml_root_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.inkml'):\n",
    "            labels = load_inkml(os.path.join(root, file))\n",
    "            symbol_list_ink = symbol_list_ink + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = Counter(symbol_list_ink).most_common()\n",
    "ink_dic = []\n",
    "for xxx in occurrences:\n",
    "    print(xxx[0])\n",
    "    ink_dic.append(xxx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ink_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tt = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "tt +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(edge_labels, start, end):\n",
    "    mask = torch.ones(end - start)\n",
    "    max_len = edge_labels.shape[0]\n",
    "    for i in range(end , start, -1):\n",
    "        if i == max_len:\n",
    "            break\n",
    "        elif (edge_labels[i-1, i] == 1):\n",
    "            pos = i - start - 1\n",
    "            mask[pos] = 0\n",
    "        else:\n",
    "            break\n",
    "    for i in range(start, end-1):\n",
    "        if (edge_labels[i-1, i] == 1):\n",
    "            pos = i - start\n",
    "            mask[pos] = 0\n",
    "        else:\n",
    "            break\n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "edge_labels = torch.tensor([[0, 1, 0, 0, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 1, 0, 0, 0, 0],[0, 0, 1, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 0],[0, 0, 0, 0, 0, 0, 0, 1],[0, 0, 0, 0, 0, 0, 1, 0]])\n",
    "max_node = 5\n",
    "start = 0\n",
    "end = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mask(edge_labels, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8, 0, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = './results/test/'\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "pred_edge = torch.zeros(0)\n",
    "pred_node = torch.zeros(0)\n",
    "gt_edge = torch.zeros(0)\n",
    "gt_node = torch.zeros(0)\n",
    "for root, _, files in os.walk(result_path):\n",
    "    for file in files:\n",
    "        pt = torch.load(os.path.join(root, file), map_location=torch.device('cpu'))\n",
    "        stroke_emb = pt[0]\n",
    "        edge_emb = pt[1]\n",
    "        stroke_label = pt[2]\n",
    "        edge_label = pt[3]\n",
    "        indices = torch.nonzero(edge_label.reshape(-1))\n",
    "        edge_emb = edge_emb.reshape(-1, edge_emb.shape[-1])[indices]\n",
    "        edge_label = edge_label.reshape(-1)[indices]\n",
    "        pred_edge = torch.cat((pred_edge, edge_emb), dim=0)\n",
    "        pred_node = torch.cat((pred_node, stroke_emb), dim=0)\n",
    "        gt_edge = torch.cat((gt_edge, edge_label), dim=0)\n",
    "        gt_node = torch.cat((gt_node, stroke_label), dim=0)\n",
    "pred_edge = pred_edge.squeeze(1)\n",
    "cm = confusion_matrix(gt_edge, torch.argmax(pred_edge, dim=1))\n",
    "cm_node = confusion_matrix(gt_node, torch.argmax(pred_node, dim=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_integers = set(torch.argmax(pred_edge, dim = 1).view(-1).numpy())\n",
    "num_unique_integers = len(unique_integers)\n",
    "print(unique_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(gt_node, torch.argmax(pred_node, dim = 1)))\n",
    "print(accuracy_score(gt_edge, torch.argmax(pred_edge, dim = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 20))  # Change the figure size as needed\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = cm.shape[0]\n",
    "class_accuracies = {}\n",
    "for i in range(num_classes):\n",
    "    class_accuracies[f\"Class_{i}\"] = cm[i, i] / cm[i].sum()\n",
    "\n",
    "# Print accuracy for each class\n",
    "for key, value in class_accuracies.items():\n",
    "    print(f\"Accuracy for {key}: {value:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = torch.load('./results/test/N11E72_UN19_1028_em_394.pt', map_location=torch.device('cpu'))\n",
    "stroke_emb = pt[0]\n",
    "edge_emb = pt[1]\n",
    "stroke_label = pt[2]\n",
    "edge_label = pt[3]\n",
    "\n",
    "print(torch.argmax(stroke_emb, dim=1))\n",
    "print(stroke_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(edge_emb, dim=2))\n",
    "print(edge_label.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_emb[1,4] + edge_emb[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_components_mask(adjacency_matrix):\n",
    "        adjacency_matrix = adjacency_matrix.cpu()\n",
    "        # batch_nb = adjacency_matrix.shape[0]\n",
    "        num_nodes = adjacency_matrix.shape[0]\n",
    "        visited = torch.zeros(num_nodes, dtype=bool)\n",
    "        def dfs(node, component):\n",
    "            visited[node] = True\n",
    "            component.append(node)\n",
    "            for neighbor in range(num_nodes):\n",
    "                if adjacency_matrix[node][neighbor] == 1 and not visited[neighbor]:\n",
    "                    dfs(neighbor, component)\n",
    "        components = []\n",
    "        for node in range(num_nodes):\n",
    "            if not visited[node]:\n",
    "                component = []\n",
    "                dfs(node, component)\n",
    "                components.append(component)\n",
    "        max_node = max(max(component) for component in components) + 1\n",
    "        mask = torch.zeros(len(components), max_node, dtype=torch.int)\n",
    "        for i, component in enumerate(components):\n",
    "            for node in component:\n",
    "                mask[i][node] = 1\n",
    "        return mask, components\n",
    "\n",
    "def sub_graph_pooling(node_feat, edge_feat):\n",
    "    am = torch.argmax(edge_feat, dim=2)\n",
    "    print(am)\n",
    "    # am = torch.zeros(node_feat.shape[0], node_feat.shape[0])\n",
    "    mask = connected_components_mask(am)\n",
    "    print(mask)\n",
    "\n",
    "\n",
    "\n",
    "    node_feat_repeat = node_feat.unsqueeze(0).repeat(mask.shape[0], 1,1)\n",
    "    node_out = torch.sum(node_feat_repeat * mask.unsqueeze(-1), dim=1)/ mask.sum(dim=1).unsqueeze(-1)\n",
    "    print(node_out.shape)\n",
    "\n",
    "    edge_out = torch.zeros(mask.shape[0], mask.shape[0], edge_feat.shape[-1])\n",
    "\n",
    "    # node_out = torch.matmul(avg_pooled_lines.t().float(), mask.float()).t()\n",
    "\n",
    "    edge_feat_repeat = edge_feat.unsqueeze(0).repeat(mask.shape[0], 1, 1, 1)\n",
    "    avg_pooled_lines = torch.sum(edge_feat_repeat * mask.unsqueeze(1).unsqueeze(-1), dim=2)/ mask.sum(dim=1).unsqueeze(1).unsqueeze(-1)\n",
    "    print(edge_feat_repeat.shape)\n",
    "    print(mask.unsqueeze(1).unsqueeze(-1).shape)\n",
    "    print(avg_pooled_lines.shape)\n",
    "    # edge_out = torch.matmul(avg_pooled_lines.permute(2,1,0).unsqueeze(1), mask.float().t().unsqueeze(2))\n",
    "    # print(torch.argmax(avg_pooled_lines,dim=2))\n",
    "    # print(avg_pooled_lines.shape)\n",
    "    edge_out_repeat = avg_pooled_lines.squeeze(-1).permute(2,1,0).unsqueeze(0).repeat(mask.shape[0],1, 1, 1)\n",
    "    edge_out_repeat = edge_out_repeat.permute(0,3,2,1)\n",
    "    print(edge_out_repeat.shape)\n",
    "    print(mask.unsqueeze(1).unsqueeze(-1).shape)\n",
    "    edge_out = torch.sum(edge_out_repeat * mask.unsqueeze(1).unsqueeze(-1), dim=2)/ mask.sum(dim=1).unsqueeze(1).unsqueeze(-1)\n",
    "    print(edge_out.shape)\n",
    "\n",
    "\n",
    "    return node_out, edge_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_out, edge_out = sub_graph_pooling(stroke_emb, edge_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(node_out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lg2symlg(edge_label, componets):\n",
    "    # node_out, edge_out = sub_graph_pooling(edge_emb)\n",
    "    # am = edge_label.where(edge_label == 1, 1, 0)\n",
    "    # mask = connected_components_mask(am)\n",
    "    symlg = torch.zeros(len(componets), len(componets))\n",
    "    for i in range(len(componets)):\n",
    "        x = edge_label[:,componets[j]]\n",
    "        y = edge_label[componets[j],:]\n",
    "        combine(x)\n",
    "        for j in componets[i]:\n",
    "            if edge_label[i][j] != 0 and edge_label[i][j] != 1:\n",
    "                symlg[i][j] = edge_label[i][j]\n",
    "                break\n",
    "    return symlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label[:,5:].shape\n",
    "torch.max(edge_label[:,5:],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(edge_label,componets):\n",
    "    for i in range(len(componets)):\n",
    "        componet = componets[i]\n",
    "        x = edge_label[:,componet]\n",
    "        x = torch.where(x==1, 0,x)\n",
    "        before_x = edge_label[:,:componet[0]]\n",
    "        after_x = edge_label[:,componet[-1] +1:]\n",
    "        x_new = torch.max(x,dim=1).values.unsqueeze(-1)\n",
    "        edge_label = torch.cat((before_x, x_new, after_x), dim=1)\n",
    "        y = edge_label[componet,:]\n",
    "        y = torch.where(y==1, 0,y)\n",
    "        y_new = torch.max(y, dim=0).values.unsqueeze(0)\n",
    "        before_y = edge_label[:componet[0],:]\n",
    "        after_y = edge_label[componet[-1]+1 :,:]\n",
    "\n",
    "        edge_label = torch.cat((before_y, y_new, after_y), dim=0)\n",
    "        gap = len(componet) - 1\n",
    "        for j in range(len(componets)):\n",
    "            for k in range(len(componets[j])):\n",
    "                componets[j][k] = componets[j][k] - gap\n",
    "        print(componets)\n",
    "        print(edge_label.shape)\n",
    "        \n",
    "    return edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, com = connected_components_mask(torch.argmax(edge_emb, dim=2))\n",
    "new = combine(edge_label, com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new)\n",
    "print(torch.argmax(edge_out, dim=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates_except_zero(list):\n",
    "    seen = {}\n",
    "    duplicate_indices = []\n",
    "\n",
    "    for i in range(len(list)):\n",
    "        if list[i] != 0:\n",
    "            if list[i]  not in seen:\n",
    "                seen[list[i]] = i\n",
    "            else:\n",
    "                # duplicate_indices[seen[list[i]]] = i\n",
    "                duplicate_indices.append([seen[list[i]], i])\n",
    "    grouped_dict = {}\n",
    "    for sublist in duplicate_indices:\n",
    "        key = sublist[0]\n",
    "        value = sublist[1:]\n",
    "        grouped_dict.setdefault(key, []).extend(value)\n",
    "    out = []\n",
    "    for key in grouped_dict:\n",
    "        out.append([key] + grouped_dict[key])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_duplicates_except_zero(tensor):\n",
    "    unique_values, _ = torch.unique(tensor, return_counts=True)\n",
    "    print(unique_values)\n",
    "    # Check if there are any duplicates (excluding 0)\n",
    "    return (unique_values != 0).any() and (len(unique_values) != len(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_with_duplicates = [1, 1, 3, 3, 4, 4,1]\n",
    "find_duplicates_except_zero(tensor_with_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeat(edge_pred):\n",
    "    for i in range(edge_pred.shape[0]):\n",
    "        repeat_x = find_duplicates_except_zero(edge_pred[i,:].tolist())\n",
    "        repeat_y = find_duplicates_except_zero(edge_pred[:,i].tolist())\n",
    "        if repeat_x != []:\n",
    "            for j in repeat_x:\n",
    "                near = [abs(x - i) for x in j]\n",
    "                keep = min(near)\n",
    "                for x in j:\n",
    "                    if x != keep:\n",
    "                        edge_pred[i,x] = 0\n",
    "        if repeat_y != []:\n",
    "            for j in repeat_y:\n",
    "                near = [abs(x - i) for x in j]\n",
    "                keep = min(near)\n",
    "                for x in j:\n",
    "                    if x != keep:\n",
    "                        edge_pred[x,i] = 0\n",
    "    return edge_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_repeat(torch.argmax(edge_out, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_all_zeros = torch.all(edge_out == 0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_directed_tree(adjacency_matrix):\n",
    "    # \n",
    "    num_nodes = adjacency_matrix.size(0)\n",
    "    \n",
    "    # 1: 1\n",
    "    num_edges = torch.sum(adjacency_matrix)\n",
    "    condition1 = (num_nodes == num_edges + 1)\n",
    "\n",
    "    # DFS\n",
    "    def dfs(node, visited):\n",
    "        visited[node] = True\n",
    "        for neighbor in range(num_nodes):\n",
    "            if adjacency_matrix[node, neighbor] == 1 and not visited[neighbor]:\n",
    "                dfs(neighbor, visited)\n",
    "\n",
    "    # \n",
    "    visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    # DFS\n",
    "    dfs(0, visited)\n",
    "\n",
    "    # 2: \n",
    "    condition2 = visited.all()\n",
    "\n",
    "    # 3: \n",
    "    condition3 = (torch.sum(adjacency_matrix) == num_nodes - 1)\n",
    "\n",
    "    # DAG\n",
    "    return condition1 and condition2 and condition3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = torch.tensor(\n",
    "        [[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    ")\n",
    "mask_tree = torch.where(tree == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_directed_tree(mask_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((0,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((0))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "root_path = '/home/e19b516g/yejing/data/data_for_graph/S150_R10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter(edges_emb, edges_label, los):\n",
    "        edges_emb = edges_emb.reshape(-1,40)\n",
    "        edges_label = edges_label.reshape(-1)\n",
    "        edges_label = torch.where(edges_label < 14, edges_label, 0)\n",
    "        indices = torch.nonzero(los.reshape(-1)).squeeze().reshape(-1)\n",
    "        edges_label = edges_label[indices]\n",
    "        edges_emb = edges_emb[indices]\n",
    "        return edges_emb, edges_label\n",
    "\n",
    "def make_data(path, tag):\n",
    "        X = torch.zeros((0,40))\n",
    "        y = torch.zeros(0)\n",
    "        for root, _, files in os.walk(os.path.join(path,tag,'los')):\n",
    "                for file in files:\n",
    "                        los = torch.from_numpy(np.load(os.path.join(root,file)))\n",
    "                        edge_emb = torch.from_numpy(np.load(os.path.join(path,tag,'edges_emb',file)))\n",
    "                        edge_labels = torch.from_numpy(np.load(os.path.join(path,tag,'edge_labels',file)))\n",
    "                        edge_emb, edge_labels = edge_filter(edge_emb, edge_labels, los)\n",
    "                        X = torch.cat((X, edge_emb))\n",
    "                        y = torch.cat((y, edge_labels))\n",
    "        torch.save(X, os.path.join(path,tag + '_edge_X.pt'))\n",
    "        torch.save(y, os.path.join(path,tag + '_edge_y.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data(root_path,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.MainModel import Edge_emb\n",
    "class Edge_emb_softmax(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.edge_emb = Edge_emb([40,384,14],0.2)\n",
    "        self.softmax= torch.nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        print(x.shape)\n",
    "        x = self.edge_emb(x).reshape(-1,14)\n",
    "        print(x.shape)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([448496, 40])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 13\u001b[0m     pred\u001b[39m=\u001b[39m model(test_X)\n\u001b[1;32m     14\u001b[0m \u001b[39m# learn = ts_learner(dataloader, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy, weights_path=pt_path)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# preds, _ = learn.get_preds()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/crohme/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m, in \u001b[0;36mEdge_emb_softmax.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 9\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_emb(x)\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/crohme/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/yejing/code/Edge_GAT/Model/MainModel.py:28\u001b[0m, in \u001b[0;36mEdge_emb.forward\u001b[0;34m(self, edge_in_features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, edge_in_features):\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_emb_parm) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 28\u001b[0m         edge_in_features \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlinear\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mstr\u001b[39;49m(i))(edge_in_features)\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     29\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m             edge_in_features \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbn\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i))(edge_in_features)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# from tsai.all import *\n",
    "# from p_train import *\n",
    "# import torch\n",
    "test_y = torch.load(os.path.join(root_path,'alledge', 'test_y.pt')).long()\n",
    "test_X = torch.load(os.path.join(root_path,'alledge', 'test_X.pt')).float()\n",
    "# datasets_test = TSDatasets(test_X.float(), test_y)\n",
    "# dataloader = TSDataLoaders.from_dsets(datasets_test, bs = 250, num_workers=0)\n",
    "pt_path = './models/edge.pth'\n",
    "model = Edge_emb_softmax()\n",
    "model.load_state_dict(torch.load(pt_path))\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    pred= model(test_X)\n",
    "# learn = ts_learner(dataloader, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy, weights_path=pt_path)\n",
    "# preds, _ = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Edge_emb_softmax(\n",
       "  (edge_emb): Edge_emb(\n",
       "    (linear0): Linear(in_features=40, out_features=384, bias=True)\n",
       "    (bn0): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation0): LeakyReLU(negative_slope=0.01)\n",
       "    (dropout0): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=384, out_features=14, bias=True)\n",
       "    (bn1): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation1): LeakyReLU(negative_slope=0.01)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (softmax): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([448496, 40])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
