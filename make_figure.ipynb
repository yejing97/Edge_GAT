{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/home/e19b516g/yejing/data/data_for_graph/S150_R10/val/los/N4E8_UN_102_em_35.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(435, 181), (437, 182), (437, 184), (437, 188), (437, 191), (437, 194), (437, 198), (436, 202), (436, 206), (436, 210), (435, 215), (435, 220), (435, 224), (435, 229), (434, 232), (434, 236), (434, 239), (434, 242), (435, 244), (435, 246), (435, 247), (435, 248), (435, 249), (436, 249), (436, 248), (437, 246), (437, 244), (438, 242), (439, 240), (441, 237), (443, 234), (445, 231), (448, 228), (452, 225), (455, 223), (457, 221), (461, 220), (464, 219), (467, 218), (471, 218), (474, 218), (477, 220), (479, 222), (482, 224), (484, 227), (486, 229), (488, 232), (489, 235), (489, 238), (489, 241), (488, 244), (487, 248), (486, 251), (484, 254), (482, 257), (479, 259), (475, 262), (471, 264), (467, 266), (463, 267), (457, 268), (452, 268), (447, 268), (444, 268), (440, 267), (437, 266), (434, 265), (432, 264), (431, 262), (430, 261), (430, 260)]\n"
     ]
    }
   ],
   "source": [
    "s1 = \"435 181, 437 182, 437 184, 437 188, 437 191, 437 194, 437 198, 436 202, 436 206, 436 210, 435 215, 435 220, 435 224, 435 229, 434 232, 434 236, 434 239, 434 242, 435 244, 435 246, 435 247, 435 248, 435 249, 436 249, 436 248, 437 246, 437 244, 438 242, 439 240, 441 237, 443 234, 445 231, 448 228, 452 225, 455 223, 457 221, 461 220, 464 219, 467 218, 471 218, 474 218, 477 220, 479 222, 482 224, 484 227, 486 229, 488 232, 489 235, 489 238, 489 241, 488 244, 487 248, 486 251, 484 254, 482 257, 479 259, 475 262, 471 264, 467 266, 463 267, 457 268, 452 268, 447 268, 444 268, 440 267, 437 266, 434 265, 432 264, 431 262, 430 261, 430 260\"\n",
    "s2 = \"500 165, 498 177, 498 180, 498 182, 498 184, 498 186, 497 187, 497 188, 497 189, 497 190, 496 189, 496 188, 496 187, 496 185, 496 183, 497 181, 498 179, 499 176, 500 174, 501 171, 502 169, 503 167, 504 166, 506 164, 508 163, 509 163, 511 163, 513 163, 514 164, 515 166, 516 168, 517 170, 517 172, 518 175, 517 177, 517 180, 517 182, 516 184, 516 186, 515 188, 515 190, 514 191, 514 192, 514 193, 513 194, 513 195\"\n",
    "def make_coor(coordinates_str):\n",
    "    coordinates_list = [map(int, coord.split()) for coord in coordinates_str.split(', ')]\n",
    "    coordinates_tuples = [(x, y) for x, y in coordinates_list]\n",
    "    return coordinates_tuples\n",
    "s1 = make_coor(s1)\n",
    "s2 = make_coor(s2)\n",
    "print(s1)\n",
    "s1 = np.array(s1)\n",
    "s2 = np.array(s2)\n",
    "# minx = min(np.min(s1, axis=0)[0], np.min(s2, axis=0)[0])\n",
    "# miny = min(np.min(s1, axis=0)[1], np.min(s2, axis=0)[1])\n",
    "ss = np.concatenate((s1, s2), axis=0)\n",
    "d = np.max(ss, axis=0) -np.min(ss, axis=0)\n",
    "s1_norm = (s1 - np.min(ss, axis=0)) / d\n",
    "s2_norm = (s2 - np.min(ss, axis=0)) / d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "PI = math.pi\n",
    "\n",
    "def fuzzy_se(op, ua):\n",
    "    return max(0, 1 -  (2/PI)*np.arccos(op.dot(ua)/np.linalg.norm(op)))\n",
    "\n",
    "def fuzzy_stroke(stroke, point_o, ua):\n",
    "    # print(stroke)\n",
    "    fuzzy_stroke = []\n",
    "    for point in stroke:\n",
    "        x_p = point[0]\n",
    "        y_p = point[1]\n",
    "        op = np.array([x_p - point_o[0], y_p - point_o[1]])\n",
    "        v_p = fuzzy_se(op, ua)\n",
    "        fuzzy_stroke.append(v_p)\n",
    "    # print(fuzzy_stroke)\n",
    "    return np.array(fuzzy_stroke).astype(np.float32)\n",
    "\n",
    "def calculate_center(stroke):\n",
    "    left = math.inf\n",
    "    right = -math.inf \n",
    "    top = -math.inf \n",
    "    bottom = math.inf \n",
    "    for x, y in stroke:\n",
    "        left = min(left, x)\n",
    "        right = max(right, x)\n",
    "        top = max(top, y)\n",
    "        bottom = min(bottom, y)\n",
    "    center_x = (left + right) / 2\n",
    "    center_y = (top + bottom) / 2\n",
    "    return [center_x, center_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "width, height = 300, 300\n",
    "# grey_values = np.random.rand(height, width)\n",
    "# scaled_grey_values = grey_values * 255\n",
    "ua_0 = np.array([0, 1])\n",
    "ua_1 = np.array([0, -1])\n",
    "ua_2 = np.array([1, 0])\n",
    "ua_3 = np.array([-1, 0])\n",
    "scaled_grey_values = np.zeros((width, height))\n",
    "s1_draw = [(int(x * width), int(y * height)) for x, y in s1_norm]\n",
    "s2_draw = [(int(x * width), int(y * height)) for x, y in s2_norm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image(s1_draw, s2_draw, ua,name):\n",
    "    center_s1 = calculate_center(s1_draw)\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            op = np.array([i- center_s1[1], j - center_s1[0]])\n",
    "            scaled_grey_values[i,j] = int(fuzzy_se(op, ua) * 255)\n",
    "\n",
    "    s2_sample = [s2_draw[0],s2_draw[5], s2_draw[10], s2_draw[15],s2_draw[20],s2_draw[25],s2_draw[30],s2_draw[35], s2_draw[40], s2_draw[45],s2_draw[-1]]\n",
    "\n",
    "    grey_image = Image.fromarray(scaled_grey_values.astype('uint8'), mode='L')\n",
    "    rgb_image = grey_image.convert('RGB')\n",
    "    # image = Image.new('L', (width, height), scaled_grey_values)\n",
    "    draw = ImageDraw.Draw(rgb_image)\n",
    "    draw.line(s1_draw, fill='red', width=3)\n",
    "    draw.line(s2_draw,fill='blue', width=3)\n",
    "    center = (center_s1[0] - 2, center_s1[1] - 2, center_s1[0] + 2, center_s1[1] + 2)\n",
    "    s2_sample = [s2_draw[0],s2_draw[7], s2_draw[14], s2_draw[21],s2_draw[28],s2_draw[35],s2_draw[42],s2_draw[49], s2_draw[56], s2_draw[63],s2_draw[-1]]\n",
    "\n",
    "    # draw.ellipse(center, fill='yellow', width=2)\n",
    "    for point in s2_sample:\n",
    "        bounding_box = (point[0] - 2, point[1] - 2, point[0] + 2, point[1] + 2)\n",
    "        draw.ellipse(bounding_box, fill='yellow', width=2)\n",
    "    rgb_image.save(str(name) + \".png\")\n",
    "    # rgb_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_image(s2_draw, s1_draw, ua_0, 'b_ua_0')\n",
    "make_image(s2_draw, s1_draw, ua_1, 'b_ua_1')\n",
    "make_image(s2_draw, s1_draw, ua_2, 'b_ua_2')\n",
    "make_image(s2_draw, s1_draw, ua_3, 'b_ua_3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_traintement import *\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "results_path = '/home/e19b516g/yejing/code/Edge_GAT/results/test'\n",
    "all_am = []\n",
    "all_gt = []\n",
    "all_node_pred = torch.zeros(0)\n",
    "all_node_gt = torch.zeros(0)\n",
    "for root, _, files in os.walk(results_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.pt'):\n",
    "                path = os.path.join(root, file)\n",
    "                stroke_emb, edge_emb, stroke_label, edge_label = load_pt(path)\n",
    "                seg_am = torch.where(torch.argmax(edge_emb, dim=2) == 1, 1, 0)\n",
    "                seg_gt = torch.where(edge_label == 1, 1, 0)\n",
    "                all_node_pred = torch.cat((all_node_pred, torch.argmax(stroke_emb, dim=1)))\n",
    "                all_node_gt = torch.cat((all_node_gt, stroke_label))\n",
    "                for i in range(seg_am.shape[0]-1):\n",
    "                    all_am.append(int(seg_am[i,i+1]))\n",
    "                    all_gt.append(int(seg_gt[i,i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8500402950839997\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(np\u001b[39m.\u001b[39marray(all_node_pred), np\u001b[39m.\u001b[39marray(all_node_gt)))\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(precision_score(np.array(all_node_pred), np.array(all_node_gt)))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(recall_score(np\u001b[39m.\u001b[39;49marray(all_node_pred), np\u001b[39m.\u001b[39;49marray(all_node_gt)))\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(f1_score(np.array(all_node_pred), np.array(all_node_gt)))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/crohme/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2098\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[1;32m   1968\u001b[0m     y_true,\n\u001b[1;32m   1969\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1976\u001b[0m ):\n\u001b[1;32m   1977\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \n\u001b[1;32m   1979\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2097\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2098\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2099\u001b[0m         y_true,\n\u001b[1;32m   2100\u001b[0m         y_pred,\n\u001b[1;32m   2101\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   2102\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   2103\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   2104\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   2105\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   2106\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   2107\u001b[0m     )\n\u001b[1;32m   2108\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/anaconda3/envs/crohme/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/crohme/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1391\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1389\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1390\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[1;32m   1394\u001b[0m         )\n\u001b[1;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[1;32m   1396\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1402\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(accuracy_score(np.array(all_node_pred), np.array(all_node_gt)))\n",
    "# print(precision_score(np.array(all_node_pred), np.array(all_node_gt)))\n",
    "print(recall_score(np.array(all_node_pred), np.array(all_node_gt), average='weighted'))\n",
    "# print(f1_score(np.array(all_node_pred), np.array(all_node_gt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632038488952245\n",
      "0.9143480632842335\n",
      "0.954985754985755\n",
      "0.9342251950947603\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(np.array(all_am), np.array(all_gt)))\n",
    "print(precision_score(np.array(all_am), np.array(all_gt)))\n",
    "print(recall_score(np.array(all_am), np.array(all_gt)))\n",
    "print(f1_score(np.array(all_am), np.array(all_gt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crohme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
